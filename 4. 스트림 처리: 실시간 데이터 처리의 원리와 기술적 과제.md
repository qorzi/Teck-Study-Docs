# 1. 이벤트(Event)란 무엇인가?

- 스트림 처리의 가장 기본적인 데이터 단위를 **이벤트(Event)** 라고 함
- 이벤트는 특정 시점에 발생한 사건에 대한 세부 정보를 담고 있는 작고, 독립적이며, **불변하는(immutable) 객체**
- **특성**: 한번 발생하면 그 내용이 변하지 않는 '사실'을 기록
- **주요 사용 예시**:
    - 사용자의 상품 구매, 웹사이트 클릭 로그
    - IoT 센서에서 수집된 온도 데이터
    - 데이터베이스의 특정 행(row) 변경 기록

# 2. 메시징 시스템: 이벤트 전달의 중추

- 이벤트는 생산자(Producer)에서 소비자(Consumer)로 전달되어야 함.
- 이 역할을 하는 것이 메시징 시스템이며, 전달 방식에 따라 나뉨.
    - **직접 메시징**: 생산자가 소비자의 네트워크 주소를 알고 직접 메시지를 전송. 간단하지만, 생산자와 소비자가 서로를 알아야 하므로 강하게 결합(tightly coupled)되고, 네트워크 장애나 소비자 장애에 취약.
    - **메시지 브로커를 통한 방식**: 중간에 메시지 브로커라는 특별한 소프트웨어를 둠. 생산자는 브로커에만 메시지를 보내고, 소비자는 브로커로부터 메시지를 가져감. 이 방식이 대부분의 스트림 처리 시스템에서 사용됨.
- 메시지 브로커는 크게 두 가지 스타일로 발전해 옴.

# 3. 전통적인 메시지 브로커 (AMQP/JMS 스타일)

- **정의**: 브로커가 메시지를 수신하고, 소비자에게 전달한 뒤 **메시지를 삭제**하는 모델
- **대표 주자**: RabbitMQ, ActiveMQ
- **주요 읽기 방식**:
    - **로드 밸런싱 (Load Balancing)**: 여러 소비자가 하나의 큐(Queue)를 구독. 브로커는 각 메시지를 하나의 소비자에게만 전달하여 작업을 분산. (메시지 처리 순서 비보장)
    - **팬아웃 (Fan-out)**: 하나의 이벤트를 여러 독립적인 소비자에게 브로드캐스팅.
- **특징**:
    - 소비자가 메시지 처리를 확인(Acknowledgement)하면 브로커에서 메시지를 삭제
    - 복잡한 라우팅 규칙을 설정하기 용이
    - **주요 용도**: 각 메시지가 독립적인 작업 단위일 때 효과적 (예: 이메일 발송, 이미지 리사이징)

# 4. 로그 기반 메시지 브로커 (Kafka 스타일)

- **정의**: 추가만 가능한(append-only) 로그에 이벤트를 **영속적으로 저장**하는 모델
- **대표 주자**: Apache Kafka, Amazon Kinesis
- **핵심 개념**:
    - **파티셔닝 (Partitioning)**: 처리량 확장을 위해 하나의 로그(토픽)를 여러 파티션으로 나눔. 파티션 내에서는 순서가 보장됨
    - **오프셋(Offset)**: 소비자가 어디까지 읽었는지 기억하는 위치. 이를 통해 언제든지 특정 시점부터 데이터를 **다시 읽기(replay)** 가능
    - **장기 저장**: 이벤트를 디스크에 저장하므로 장기간 보관 가능

# 5. 메시지 브로커 비교: 전통 방식 vs 로그 기반

| 구분 | 전통적 브로커 (AMQP/JMS) | 로그 기반 브로커 (Kafka) |
| --- | --- | --- |
| **메시지 보관** | 소비 후 삭제 | 영속적 저장 (설정에 따라) |
| **소비자 모델** | 서버 중심 (브로커가 푸시) | 클라이언트 중심 (소비자가 풀) |
| **순서 보장** | 큐 내에서는 보장, 로드밸런싱 시 비보장 | 파티션 내에서 엄격히 보장 |
| **다시 읽기** | 기본적으로 불가능 | 오프셋을 통해 언제든 가능 |
| **주요 용도** | 비동기 작업 처리, 태스크 큐 | 실시간 데이터 파이프라인, 이벤트 소싱 |

# 6. 스트림 처리의 3가지 주요 목적

1. **복잡한 이벤트 처리 (CEP, Complex Event Processing)**
    - 특정 순서나 조합으로 발생하는 이벤트 '패턴'을 감지하는 데 사용
    - **예시**: "사용자가 1분 안에 장바구니에 상품을 3번 담았지만, 구매는 하지 않은 경우"를 감지하여 쿠폰 발송
2. **스트림 분석 (Stream Analytics)**
    - 대량의 이벤트 스트림을 기반으로 통계적 지표를 집계하고 분석
    - **윈도우(Window)** 라는 고정된 시간 간격을 기준으로 집계하는 것이 일반적 (예: 지난 5분간의 웹사이트 방문자 수)
    - **대표 주자**: Apache Flink, Spark Streaming, Kafka Streams
3. **구체화 뷰 유지 (Materialized View Maintenance)**
    - 이벤트 스트림을 처리하여 파생된 데이터(결과)를 최신 상태로 유지하는 것
    - **스트림 상에서 검색**: 전통적인 검색 엔진이 '데이터를 저장하고 질의를 실행'하는 반면, 스트림 검색은 '질의를 먼저 저장하고 스트림에서 데이터가 오면 매칭'
    - **예시**: 부동산 웹사이트에서 사용자가 설정한 검색 조건과 일치하는 새 매물이 등록되면 즉시 알림을 보내는 기능

# 7. 스트림 처리의 기술적 과제: 시간

- **문제점: 이벤트 시간 vs 처리 시간**
    - **이벤트 시간 (Event Time)**: 이벤트가 실제로 발생한 시간
    - **처리 시간 (Processing Time)**: 스트림 처리자가 이벤트를 처리한 시간
    - 네트워크 지연 등으로 이벤트가 발생 순서대로 도착하지 않을 수 있음(이를 **'낙오자(straggler)'** 이벤트라 함). 처리 시간을 기준으로 작업하면 결과가 왜곡될 수 있음
- **해결책**: 대부분의 현대 스트림 처리 프레임워크는 **이벤트 시간**을 기준으로 윈도우를 정의하고, 낙오자 이벤트를 처리하기 위한 정책(예: 특정 시간까지 기다리기)을 제공

# 8. 스트림 처리의 기술적 과제: 윈도우 유형

- 무한한 스트림을 유한한 덩어리로 나누기 위해 윈도우를 사용
- **텀블링 윈도우 (Tumbling Window)**: 시간이 겹치지 않는 고정된 크기의 윈도우 (예: 10:00-10:05, 10:05-10:10)
- **홉핑 윈도우 (Hopping Window)**: 시간이 겹치는 고정된 크기의 윈도우 (예: 10:00-10:05, 10:01-10:06)
- **슬라이딩 윈도우 (Sliding Window)**: 이벤트가 도착할 때마다 그 이벤트를 포함하는 윈도우를 생성
- **세션 윈도우 (Session Window)**: 활동이 없을 때까지(timeout) 윈도우가 계속 확장됨. 사용자의 활동 단위를 묶는 데 유용

# 9. 스트림 처리의 기술적 과제: 조인

- **스트림-스트림 조인 (윈도우 조인)**: 두 개의 다른 이벤트 스트림을 조인. (예: '상품 클릭' 스트림과 '상품 장바구니 추가' 스트림을 사용자 ID로 조인). 특정 시간 윈도우 내에서 발생하는 이벤트끼리 묶어야 함
- **스트림-테이블 조인 (스트림 강화)**: 이벤트 스트림에 데이터베이스나 키-값 저장소의 데이터를 추가하여 정보를 풍부하게 만듦. (예: 사용자 ID만 있는 이벤트에 DB에서 사용자 이름, 등급 정보를 가져와 추가)
- **테이블-테이블 조인 (구체화 뷰 유지)**: 변경 데이터 캡처(CDC)를 통해 두 테이블의 변경 스트림을 조인하여, 두 테이블이 조인된 결과에 대한 구체화 뷰를 유지

# 10. 스트림 처리의 기술적 과제: 내결함성

- **질문**: "무한한 스트림은 어떻게 장애를 복구하는가?"
- **해결책 1: 마이크로 일괄 처리와 체크포인트**
    - **Spark Streaming**: 스트림을 작은 일괄 처리(micro-batch)로 나누어 처리
    - **Flink**: 주기적으로 연산자의 상태(state) 스냅샷을 찍어 영속적인 저장소에 기록(체크포인트). 장애 발생 시 가장 최근의 체크포인트에서 상태를 복구하고 이후의 이벤트를 다시 처리
- **해결책 2: 정확히 한 번 처리 (Exactly-once Semantics)**
    - 장애가 발생해도 모든 이벤트가 정확히 한 번만 처리된 것처럼 보이게 하는 것이 목표
    - **멱등성(Idempotence)**: 같은 연산을 여러 번 수행해도 결과가 동일한 성질. 실패한 작업을 재시도할 때 부작용이 없도록 보장
    - **원자적 커밋(Atomic Commit)**: 이벤트 처리와 상태 업데이트, 출력까지 모든 작업이 하나의 트랜잭션처럼 동작하게 하여, 중간에 실패하면 모두 롤백되도록 함

# 11. 데이터베이스와 스트림의 통합

- **핵심 아이디어**: 데이터베이스의 변경 로그를 이벤트 스트림으로 간주하여 여러 시스템을 손쉽게 통합
- **이벤트 소싱 (Event Sourcing)**
    - 애플리케이션의 모든 상태 변화를 이벤트의 로그로 저장하는 아키텍처 패턴.
    - 현재 상태는 이 이벤트 로그를 처음부터 끝까지 재생하여 복구 가능
- **변경 데이터 캡처 (Change Data Capture - CDC)**
    - 데이터베이스의 변경 로그(Transaction Log)를 이벤트 스트림으로 간주하는 기술
    - **장점**:
        - 검색 색인, 캐시, 분석 시스템 등 다양한 파생 데이터 시스템을 항상 최신 상태로 유지 가능
        - 처음부터 모든 변경 로그를 소비하면, 기존 데이터로 완전히 새로운 뷰(View)나 시스템을 구축하는 것도 가능