# 1. 분산 파일 시스템 (DFS) 이란?

- **"네트워크로 연결된 여러 서버를 하나의 파일 시스템처럼 사용하게 하는 기술"**
- **목적**: 중앙 집중식 시스템의 용량, 성능, 가용성 한계를 극복
- **핵심 특징**:
    - **투명성**: 사용자는 데이터의 물리적 위치를 몰라도 됨
    - **확장성**: 서버(노드) 추가만으로 용량 무한 확장 (Scale-out)
    - **고가용성**: 데이터 복제로 서버 장애 시에도 데이터 유실 방지
    - **데이터 공유**: 원격에서 대용량 데이터 동시 접근 및 공유

# 2. HDFS 아키텍처 (Hadoop Distributed File System)

- 구글 파일 시스템(GFS) 기반의 오픈소스 DFS. 하둡 생태계의 핵심 저장소
- **핵심 구조**: 마스터-슬레이브 구조
    - **네임노드 (마스터)**: 파일 시스템의 모든 메타데이터(파일 구조, 블록 위치 등)를 관리하는 두뇌
    - **데이터노드 (슬레이브)**: 실제 데이터 블록을 저장하고, 네임노드의 지시를 따르는 일꾼
- **데이터 저장 방식**: 파일을 고정된 크기(기본 128MB)의 **블록(Block)** 단위로 쪼개서 분산 저장

# 3. HDFS의 핵심 원리 1: 내결함성

- 저렴한 범용 하드웨어의 잦은 고장을 전제로 설계됨
- **블록 복제**: 각 데이터 블록을 여러 개(기본 3개) 복제해 서로 다른 서버에 저장
- **랙 인식**: 데이터센터의 물리적 랙(Rack) 구조를 인지하여, 랙 단위 장애에도 대비
- **장애 감지 및 복구**: 데이터노드가 주기적으로 보내는 **하트비트(Heartbeat)** 로 장애를 감지하고, 블록을 자동 복구
- **데이터 무결성**: **체크섬(Checksum)** 을 사용해 데이터 손상 여부를 검증하고 복구

# 4. HDFS의 핵심 원리 2: 데이터 지역성 (Data Locality)

- **핵심 철학**: "데이터를 옮기지 말고, 연산을 데이터가 있는 곳으로 보내라"
- **동작 방식**: 데이터 처리 로직(MapReduce)을 데이터가 저장된 데이터노드로 보내 로컬에서 처리
- **효과**: 네트워크 병목을 최소화하고, 대규모 데이터 처리량 극대화

# 5. HDFS의 한계와 다음 패러다임

- **장점**: 대용량 파일 저장 및 배치(Batch) 처리에 매우 효율적
- **한계점**:
    - **비효율적인 분석**: 데이터의 의미(스키마)를 몰라, 간단한 분석에도 전체 파일을 스캔해야 함
    - **낮은 유연성**: 데이터 수정/삭제가 거의 불가능 (Write-Once-Read-Many 모델)
    - **실시간 처리 불가**: 배치 처리에 최적화되어 대화형 쿼리에 부적합
- **결론**: 단순 저장을 넘어, 데이터를 구조화하고 빠르게 분석할 필요성 대두 → **데이터 웨어하우스(DW)** 의 탄생으로 이어짐

# 6. 데이터 웨어하우스 (DW) 란?

- **"기업의 의사결정 지원을 위해, 주제별로 통합된 데이터를 저장하는 중앙 저장소"**
- **핵심 특성**:
    - **주제 지향적**: '고객', '매출' 등 비즈니스 주제 중심으로 데이터 구성
    - **통합적**: 전사 데이터를 일관된 형식으로 통합. **"단일 진실 공급원(Single Source of Truth)"** 역할
    - **시계열성**: 시간의 흐름에 따른 변화와 추세 분석이 가능하도록 데이터 저장
    - **비휘발성**: 적재된 데이터는 수정/삭제하지 않고 분석의 안정성 보장

# 7. DW의 핵심 원리: Schema-on-Write

- **"쓰기 시 스키마 적용"**
- **동작 방식**: 데이터를 저장하기 전에 **반드시 엄격한 스키마를 정의**하고, 모든 데이터를 이 스키마에 맞춰 변환(Transform)한 후 적재(Load)
- **데이터 파이프라인**: **ETL (Extract, Transform, Load)**
    1. 데이터 **추출(Extract)**
    2. DW 스키마에 맞게 **변환(Transform)**
    3. DW에 **적재(Load)**
- **결과**: 데이터 품질과 신뢰성이 매우 높음

# 8. DW의 한계와 다음 패러다임

- **장점**: 정형 데이터에 대한 빠르고 신뢰성 있는 BI 및 리포팅 제공
- **한계점**:
    - **유연성 부재**: 스키마 변경 시, 값비싼 ETL 파이프라인 전체를 수정해야 함
    - **비정형 데이터 처리 불가**: 이미지, 텍스트, 로그 등 현대 데이터 과학의 핵심 재료를 다룰 수 없음
    - **탐색적 분석의 어려움**: 정제된 데이터만 존재해, 원본(Raw) 데이터를 자유롭게 분석하기 어려움
- **결론**: 모든 형태의 데이터를 원본 그대로 저장해두고 싶다는 요구 발생 → **데이터 레이크(Data Lake)**의 탄생으로 이어짐

# 9. 데이터 레이크 (Data Lake) 란?

- **"모든 형태(정형, 반정형, 비정형)의 데이터를 원본 형식 그대로 저장하는 중앙 저장소"**
- **등장 배경**: DW의 낮은 유연성과 비정형 데이터 처리 한계를 극복하기 위함
- **목적**: 데이터 과학자들이 방대한 원시 데이터를 기반으로 자유로운 탐색적 분석과 머신러닝 모델 개발을 수행하도록 지원

# 10. 데이터 레이크의 핵심 원리: Schema-on-Read

- **"읽기 시 스키마 적용"**
- **동작 방식**: 데이터는 스키마 없이 원본 그대로 저장. 분석을 위해 **데이터를 읽는 시점**에 스키마를 적용
- **데이터 파이프라인**: **ELT (Extract, Load, Transform)**
    1. 데이터 **추출(Extract)**
    2. 데이터 레이크에 원본 그대로 **적재(Load)**
    3. 분석 필요 시 **변환(Transform)**
- **결과**: 데이터 수집 속도가 빠르고, 미래의 용도를 미리 결정할 필요 없어 유연성이 극대화됨

# 11. 데이터 레이크의 도전 과제: 데이터 스웜프 (Data Swamp)

- **"데이터 늪"**
- **정의**: 데이터 거버넌스 없이 무분별하게 데이터를 쌓아, 출처나 품질을 알 수 없고 검색조차 불가능해진 데이터의 무덤
- **문제점**: 데이터 레이크의 최대 장점인 유연성이 관리 부재 시 최악의 단점으로 변질
- **해결책**: 강력한 **데이터 거버넌스**와 체계적인 **메타데이터 관리**

# 12. 데이터 레이크의 한계와 다음 패러다임

- **장점**: 모든 데이터를 저렴한 비용으로 유연하게 저장. 데이터 과학 및 AI 모델 개발에 필수적
- **한계점**:
    - **신뢰성 부재**: ACID 트랜잭션 미지원으로 데이터 일관성 유지가 어렵고, 데이터 품질 보장이 힘듦
    - **성능 문제**: BI 도구에서 직접 쿼리하기에는 성능이 너무 느림
    - **비효율적 2계층 아키텍처**: 결국 레이크의 데이터를 다시 ETL하여 DW로 옮기는 데이터 중복과 관리 복잡성 발생
- **결론**: '레이크의 유연성'과 '웨어하우스의 신뢰성'을 모두 원하게 됨 → **레이크하우스(Lakehouse)** 의 탄생으로 이어짐

# 13. 레이크하우스 (Lakehouse) 란?

- **"데이터 레이크의 유연성 + 데이터 웨어하우스의 신뢰성"**
- **정의**: 데이터 레이크(주로 클라우드 객체 스토리지) 위에 직접 데이터 웨어하우스의 핵심 기능들을 구현한 차세대 단일 데이터 플랫폼
- **목표**: BI와 AI를 위한 별도의 데이터 사일로를 제거하고, 모든 데이터 워크로드를 단일 시스템에서 처리

# 14. 레이크하우스의 핵심 기능

- 데이터 레이크 위에서 아래 기능들을 직접 제공
- **ACID 트랜잭션**: 데이터 작업의 원자성, 일관성을 보장하여 신뢰성 확보
- **스키마 강제 및 진화**: 데이터 품질을 보장하면서도, 유연한 스키마 변경 지원
- **시간 여행 (Time Travel)**: 데이터의 모든 변경 이력을 버전으로 관리하여 특정 시점 조회나 복구 가능
- **배치 및 스트리밍 통합**: 단일 아키텍처에서 배치와 실시간 스트림 처리 모두 지원
- **직접적인 BI 쿼리**: 고성능 쿼리 엔진을 통해 BI 도구가 데이터 레이크를 직접 분석

# 15. 핵심 기술: 오픈 테이블 포맷

- 레이크하우스 기능을 구현하는 기술적 토대. 파일 집합을 신뢰할 수 있는 '테이블'로 만들어 줌
- **대표 주자**: **Delta Lake, Apache Iceberg, Apache Hudi**

| 특징 | 델타 레이크 (Delta Lake) | 아파치 아이스버그 (Apache Iceberg) | 아파치 후디 (Apache Hudi) |
| --- | --- | --- | --- |
| **기본 원리** | 파일 레벨 작업의 트랜잭션 로그 | 파일 목록의 스냅샷을 통한 테이블 상태 관리 | 인덱스를 통한 레코드 레벨 업데이트/삭제 |
| **주요 생태계** | 데이터브릭스/스파크와 깊은 통합 | 엔진 독립적 (Spark, Flink, Trino 등) | 스트리밍(Flink, Spark)에 강점 |
| **스키마 진화** | 지원 | 완벽 지원 | 지원 |
| **시간 여행** | 버전 또는 타임스탬프로 지원 | 스냅샷으로 지원 | 증분 쿼리 및 스냅샷으로 지원 |

# 16. 대표 아키텍처: 메달리온 (Medallion)

- 레이크하우스 내에서 데이터의 품질을 점진적으로 높여가는 데이터 설계 패턴
- **데이터 흐름**:
    - **브론즈 (Bronze)**: 모든 원천 데이터를 원본 그대로 저장
    - **실버 (Silver)**: 브론즈 데이터를 정제, 필터링, 보강한 데이터
    - **골드 (Gold)**: 특정 비즈니스 목적에 맞게 집계된 최종 데이터 (BI 대시보드, 리포팅용)

# 17. 결론: 데이터 아키텍처 진화의 정점

- **DFS**: 대용량 **저장**의 문을 염
- **DW**: 정형 데이터 **분석**과 **신뢰성**을 제공
- **Data Lake**: 모든 데이터의 **유연한** 저장을 가능케 함
- **Lakehouse**: **'신뢰성'과 '유연성'** 이라는 오랜 대립을 해소하고, BI와 AI를 위한 데이터 플랫폼을 하나로 통합. 이는 데이터 관리의 복잡성을 줄이고, 진정한 데이터 기반 혁신을 가속화하는 중요한 전환점.