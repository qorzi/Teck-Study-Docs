[PPT 슬라이드 바로가기](https://g.co/gemini/share/742f6ad5aeb5)

# 1. OLAP를 아시나요?

- olap라는 단어 들어보셨나요?
- 그렇다면, oltp는 들어보셨나요?
- 아시는 분은, 간단하게 설명해주세요!

# 2. OLTP

### **OLTP란? (Online Transaction Processing)**

- 실시간 트랜잭션 처리에 최적화된 시스템
- 지연 시간이 낮은 읽기와 쓰기 처리가 핵심

### 주요 특징

- **빠른 응답 속도:** 지연 시간이 낮은 읽기/쓰기 처리
- **동시성 제어:** 다수의 사용자가 동시에 데이터 수정 가능
- **데이터 무결성:** 트랜잭션을 통해 데이터의 정확성 보장

### 대표적인 사용 예시

- "고객의 최근 주문 정보를 조회하고, 장바구니에 담긴 상품을 결제한다”

# 3. OLAP의 등장 이유

### 그런데… 이런 질문은 어떨까?

- 질의 예시: “상반기 각 브랜드의 상품 카테고리 별 판매 수량 및 수익은?”
- 조건1. 입점 브랜드가 수 백이 넘고 상품 카테고리도 수 백개라면?
- 조건2. 정리할 정보가 여러 테이블로 나눠있고, 다대다 관계라면?
- 조건3. 쇼핑몰 하루 판매 건수가 대략 10만건이라면?
- → 과연 이 질의를 OLTP에서 실행 시키면 어떻게 될까?
    - 아마도,
    - 해당 질의 결과는 한참 뒤에야 나올 것이고, 해당 트랜젝션이 처리되는 동안 동시 실행되는 트랜잭션의 성능은 저하
    - 이 문제는 빠른 실시간 처리가 중요한 OLTP에는 중요한 문제

# 4. OLAP

### **OLAP의 등장 (Online Analytical Processing)**

- 데이터 분석에 최적화된 시스템
- 원시 데이터를 집계하고 통계를 내는 복잡한 분석 쿼리에 특화

### **주요 특징**

- **읽기 최적화:** 복잡하고 무거운 분석 쿼리를 빠르게 처리
- **대용량 데이터 처리:** 페타바이트(PB)급 데이터도 효율적으로 분석
- **데이터 적재:** ETL, 배치, 스트리밍 등 주기적으로 데이터를 가져옴

### **대표적인 사용 예시**

"지난 분기 지역별, 제품별 매출 동향을 분석하고 다음 분기 전략을 수립한다"

# 5. OLAP는 어떻게 분석에 특화되었을까

- 핵심 비결은 데이터를 저장하는 **구조의 차이**에 존재

### **로우(Row) 지향 저장**

- 한 레코드(행)의 모든 정보를 함께 저장 → OLTP에 적합

### **칼럼(Column) 지향 저장**

- 각 칼럼(열)의 데이터를 개별적으로 모아서 저장 → OLAP에 적합

# 6. 로우 지향 DB

- 로우 지향 구조는 한 줄(로우)에 레코드의 모든 값을 저장하는 방식
- 각 레코드의 모든 칼럼 값이 한 줄에 연속적으로 저장
- 특정 레코드 하나를 읽거나 수정할 때 매우 효율적
- 그래서, 실시간 트랜잭션 처리(OLTP)에 많이 사용

# 7. 로우 지향 구조 예시

- 아래와 같은 테이블이 존재한다고 해보자.
    
    
    | **학생ID** | **이름** | **나이** | **성별** | **학년** |
    | --- | --- | --- | --- | --- |
    | 1 | 홍길동 | 18 | 남 | 2 |
    | 2 | 김민수 | 17 | 남 | 1 |
    | 3 | 이영희 | 18 | 여 | 2 |
- 로우 지향은 한줄에 한 레코드의 정보를 모두 담을 것이다.
    
    ```
    학생ID,이름,나이,성별,학년
    1,홍길동,18,남,2
    2,김민수,17,남,1
    3,이영희,18,여,2
    ```
    
- 만약, 새로운 학생을 추가한다면? 로우 한줄을 추가하면 끝 → 트랜젝션 처리에 효율적
    
    ```
    4,임희상,31,남,4
    ```
    
- 만약, 학생 ID가 1인 홍길동의 정보를 가져오려면? 디스크의 한 부분만 읽으면 됨

# 8. 칼럼 지향 DB

- 칼럼 지향 구조는 로우와 반대로 한 줄에 모든 레코드의 칼럼 값을 저장하는 방식
- 필요한 칼럼만 읽어서 I/O를 줄이고, 압축 효율이 높아 대용량 분석에 적합
- 생각해보자.
    - 쿼리 범위에 해당하는 로우 데이터가 페타바이트 수준이라면,
    - 로우 지향 DB는 필요 없는 칼럼 정보도 색인하고 로드하므로 엄청난 낭비가 발생
    - 칼럼 지향 DB은 필요한 데이터(칼럼)만 읽기 때문에 쿼리 범위가 클수록 효율적
    - 예를 들어, 1월 전체 판매 수익이 필요하다면, 판매 수익에 해당하는 칼러면 읽으면 됨

# 9. 칼럼 지향 구조 예시

- 아래와 같은 테이블이 존재한다고 해보자.
    
    
    | **학생ID** | **이름** | **나이** | **성별** | **학년** |
    | --- | --- | --- | --- | --- |
    | 1 | 홍길동 | 18 | 남 | 2 |
    | 2 | 김민수 | 17 | 남 | 1 |
    | 3 | 이영희 | 18 | 여 | 2 |
- 칼럼 지향은 한줄에 한 칼럼의 정보를 모두 담을 것이다. ( 정렬된 상태로 )
    
    ```
    학생ID: 1,2,3
    이름: 홍길동,김민수,이영희
    나이: 18,17,18
    성별: 남,남,여
    학년: 2,1,2
    ```
    
- 만약, 전체 학생의 평균 나이가 궁금하다면? 나이 칼럼만 읽어 평균을 구하면 됨 → 대용량 읽기에 효율적

# 10. 칼럼 지향 구조의 최적화: 칼럼 압축

- 칼럼 지향 구조는 동일한 타입의 데이터가 모여있어 압축 효율이 매우 높음
- 특히 고유 값(Cardinality)이 적은 칼럼에서 효과적
- **비트맵 부호화와 실행 길이 부호화** 같은 압축 기법을 사용해 디스크 처리량 줄임

### **비트맵 부호화(bitmap encoding)**

- 일반적으로, 칼럼의 고유 값의 수는 로우 수에 비해 적다.
    - 고유 값의 수가 N개라면 N개의 개별 비트맵으로 변환할 수 있다는 말이다.
        - 위 학생 테이블에서 학년은 1~5로 고작 5 개. 학생 수는 수 만일 수 있음
- 비트맵 부호화는 개별 비트맵에 학년과 같은 고유 값의 위치를 비트로 표시하는 것

### 실행 길이 부호화(run-length encoding)

- 연속된 값을 개수로 치환하여 압축 저장
- 고유값이 적고, 데이터가 많을수록 압축 효율이 증가함

# 11. 부호화 예시

### 비트맵 부호화

```
성별: 남,남,남,여,여,여,남,남
---
성별 = 남: 1 1 1 0 0 0 1 1
성별 = 여: 0 0 0 1 1 1 0 0
```

- 만약, 여자인 학생의 평균 나이가 궁금하다면? 비트 정보를 통해 빠른 조건 검색으로 통계 가능

### 실행 길이 부호화

```
성별: 남,남,남,여,여,여,남,남
---
성별 = (남, 3), (여, 3), (남, 2)
```

- 8개의 데이터가 6개로 줄어듬 → 데이터가 많을수록 압축 효율 증가

# 12. 그래서, OLAP를 써야 할까?

- 대용량 데이터를 분석하고 비지니스 인사이트를 얻어야 한다면, 정답은 “YES”
- 비트맵 부호화는 정말 간단한 예시일 뿐, 차원 쿼리 최적화를 위한 다양한 기법을 사용함
- 결과적으로, 디스크 I/O와 메모리 사용량을 줄여, 대용량 데이터에서도 압도적으로 빠른 쿼리 응답이 가능
- 다만, OLAP에서 레코드 단위 쿼리를 요구하는 경우, 해당 처리는 상대적으로 느림

### 예시 쿼

```sql
-- SELECT * FROM sales; -- 전체 칼럼 조회는 피하세요!

SELECT
  brand_name,
  category,
  SUM(sales_amount) as total_sales
FROM sales
WHERE event_date BETWEEN '2024-01-01' AND '2024-06-30' -- 시간 범위 지정은 필수!
GROUP BY brand_name, category;
```

# 13. OLTP와 OLAP 비교

| 특성 | OLTP  | OLAP |
| --- | --- | --- |
| 주요 목적 | 실시간 트랜잭션 처리 | 분석, 리포팅, 의사결정 지원 |
| 주요 읽기 패턴 | 적은 수의 레코드, 키 기준 조회 | 많은 레코드에 대한 집계/통계 |
| 주요 쓰기 패턴 | 임의 접근, 사용자 입력을 낮은 지연 시간으로 기록 | 대규모 불러오기(bulk import, ETL) 또는 이벤트 스트림 |
| 주요 사용자 | 웹 애플리케이션을 통한 최종 사용자/소비자 | 의사결정 지원을 위한 내부 분석가 |
| 사용자 규모 | 다수 | 소수 |
| 데이터 표현 | 데이터의 최신 상태 (현재시점) | 과거부터 누적된 이벤트 데이터 |
| 데이터셋 크기 | GB ~ TB | TB ~ PB |
| 저장 구조 | 로우 지향 | 칼럼 지향 |

# 14. OLAP 대표 주자: Redshift vs Druid

- 그렇다면, 분석에 특화된 OLAP 시스템에는 어떤 것들이 있을까
- 대표적인 두 가지, 레드시프트와 드루이드를 통해 그 특징을 알아보자

| 구분 | Amazon Redshift | Apache Druid |
| --- | --- | --- |
| 핵심 컨셉 | 클라우드 데이터 웨어하우스 | 실시간 분석 데이터베이스 |
| 강점 | 대용량 데이터 조인, ANSI SQL 지원 | 실시간 데이터 수집 및 초고속 집계 |
| 주요 용도 | 비즈니스 인텔리전스(BI), 정기 리포트 | 실시간 대시보드, 운영 인텔리전스 |

# 15. Redshift: 대용량 분석을 위한 데이터 웨어하우스

- **레드시프트**는 AWS에서 제공하는 클라우드 기반 데이터 웨어하우스(Data Warehouse)
- 페타바이트급 대용량 데이터의 복잡한 조인과 집계 쿼리에 강점

### 주요 특징

- **강력한 SQL 지원**: 완전한 **ANSI SQL**을 지원하고, 대용량 테이블 간의 복잡한 **JOIN** 연산도 안정적으로 처리
- **다양한 데이터 포맷**: 정형 데이터뿐만 아니라 JSON, Avro 등 반정형 데이터도 바로 조회하고 분석 가능
- **배치 데이터 적재**: 대량의 데이터를 한 번에 적재하는 **배치(Batch) 적재**에 최적화 (주로 `COPY` 명령어 사용)
- **결과 캐싱**: 반복 실행되는 쿼리는 결과를 캐싱하여 두 번째 실행부터는 매우 빠른 응답 속도

# 16. Redshift의 쿼리 최적화 비결: 정렬키와 존맵

- 레드시프트는 어떻게 빠른 분석 성능을 낼까?
- 칼럼 지향 저장 방식에 더해 **정렬키(Sort Key)**와 **존맵(Zone Map)**이라는 강력한 기능

### **정렬키 (Sort Key)**

- 테이블 생성 시 특정 칼럼을 '정렬 기준'으로 지정
- 데이터는 이 정렬키 순서대로 디스크에 저장
- `WHERE` 절에 정렬키 조건이 들어오면, **필요한 데이터 블록만 읽어** 디스크 I/O가 획기적으로 감소

### **존맵 (Zone Map)**

- 각 데이터 블록(1MB)마다 칼럼의 **최소값(MIN)/최대값(MAX)**을 메타데이터로 저장
- 쿼리 조건이 블록의 MIN/MAX 범위에 해당하지 않으면, **해당 블록 전체를 읽지 않고 스킵**

# 17. Druid: 실시간 OLAP 분석의 강자

- **드루이드**는 실시간 데이터 스트림을 수집하고 즉시 분석하는 데 특화된 오픈소스 OLAP 데이터베이스
- 특히, **시간 기반 데이터(Time-series Data)**의 빠른 집계와 필터링에 독보적인 성능

### 주요 특징

- **실시간 데이터 수집**: **카프카(Kafka)** 같은 이벤트 스트림에서 데이터를 지연 없이 바로 로드하여 분석 가능
- **사전 집계 (Rollup)**: 데이터 저장 시점에 지정된 차원과 시간 단위로 메트릭 데이터를 미리 집계. 이를 통해 원본 데이터 대비 저장 공간을 크게 줄이고 쿼리 속도를 극대화
    - **차원(Dimension)**: 데이터를 분석하는 기준 (예: 브랜드, 상품 카테고리, 지역)
    - **측정값(Metric)**: 집계 대상이 되는 값 (예: 판매량, 수익)
- **세그먼트 기반 저장**: 데이터를 **시간 단위의 세그먼트(Segment)**로 분할하여 저장하고, 각 세그먼트를 병렬로 처리하여 쿼리 속도를 획기적으로 높임
- **제한적인 SQL**: SQL을 지원하지만 복잡한 조인(Join) 기능은 제한적. 대신 집계와 다차원 분석 분야에서 성능 최

# 18. Druid의 핵심 기술: 롤업(Rollup) 예시

### 원본 데이터

| **시간(분)** | **지역** | **제품** | **판매량** |
| --- | --- | --- | --- |
| 09:00 | 서울 | A | 10 |
| 09:00 | 서울 | A | 5 |
| 09:00 | 부산 | B | 7 |
| 09:05 | 서울 | A | 8 |
| 09:05 | 부산 | B | 3 |

→ `시간(분)`, `지역`, `상품`을 차원으로, `판매량`을 메트릭으로 롤업을 적용하면, 아래와 같이 데이터가 미리 집계되어 저장

### 롤업 적용 데이터

| **시간(분)** | **지역** | **제품** | **판매량(합계)** |
| --- | --- | --- | --- |
| 09:00 | 서울 | A | 15 |
| 09:00 | 부산 | B | 7 |
| 09:05 | 서울 | A | 8 |
| 09:05 | 부산 | B | 3 |

→ 원본 데이터 2건이 1건으로 집계되어 저장 용량이 줄고, `SUM(판매량)` 쿼리 시 연산할 데이터가 줄어들어 속도가 빨라

# 19. OLAP, 데이터는 어떻게 가져올까?

- OLAP 시스템은 자체적으로 데이터를 생산 X
- OLTP 시스템이나 로그 데이터 등 다양한 소스로부터 데이터를 가져와 적재
- 이 과정을 ETL(Extract, Transform, Load)이라고 부름

### ETL

- **Extract (추출)**: 소스 데이터베이스, 로그 파일 등 원본 데이터 소스에서 데이터 수집
- **Transform (변환)**: 데이터를 분석에 적합한 형태로 가공, 정제, 집계 (예: 날짜 형식 통일, 불필요한 칼럼 제거, 데이터 조인)
- **Load (적재)**: 변환된 데이터를 최종 목적지인 OLAP 시스템(데이터 웨어하우스)에 저장

# 20. ETL의 종류

- ETL은 크게 **배치 ETL**과 **스트리밍 ETL**로 나뉨
- 배치 ETL
    - 하루 동안 쌓인 방대한 데이터를 한 번에 처리하여 레드시프트 같은 데이터 웨어하우스에 적재하는데 적합
    - 이를 통해, 정제된 데이터를 바탕으로 비지니스 리포트를 작성할 수 있음
- 스트리밍 ETL
    - 사용자의 행동 로그나 센서 데이터처럼 끊임없이 발생하는 이벤트를 실시간으로 변환하여 드루이드에 적재
    - 이를 통해, 실시간 현황 대시보드를 구성할 수 있음

### 배치 ETL vs 스트리밍 ETL

| 구분 | 배치 ETL (Batch ETL) | 스트리밍 ETL (Streaming ETL) |
| --- | --- | --- |
| 처리 단위 | 대용량 데이터 묶음 (시간, 일, 주 단위) | 개별 데이터 또는 작은 데이터 묶음 (실시간) |
| 처리 시점 | 정해진 스케줄에 따라 주기적으로 실행 | 데이터가 발생하는 즉시 처리 |
| 특징 | 복잡하고 무거운 변환 작업에 유리 | 낮은 지연 시간과 빠른 데이터 반영이 핵심 |
| 주요 조합 | 데이터 소스 → Spark/Airflow → Redshift | Kafka/Kinesis → Flink/Spark Streaming/Nifi → Druid |

<aside>
💡

참고로, Spark는 내부적으로 칼럼 구조의 자료 구조인 DataFrame을 사용하고, 분산 환경에서 작업을 나눠 처리하는 방식을 사용해 빠름. (In Memory 방식)

</aside>

# 21. OLAP를 위한 데이터 파이프라인

### **배치 분석 파이프라인 (BI 및 정기 리포트용)**

> 운영 DB/로그 → [배치 ETL (Spark, Airflow)] → [Redshift (Data Warehouse)] → [BI 툴 (Tableau, Looker, Redash)]
> 
- **목표**: 비즈니스 현황 분석, 수익 리포트, 장기적인 트렌드 예측
- **특징**: 대용량 데이터를 안정적으로 처리하고 복잡한 분석 쿼리를 지원

### **실시간 분석 파이프라인 (실시간 대시보드용)**

> 이벤트/로그 스트림 (Kafka, Kinesis) → [스트리밍 ETL (Flink, Nifi)] → [Druid (Real-time OLAP)] → [실시간 대시보드(Grafna)]
> 
- **목표**: 서비스 이상 징후 감지, 실시간 사용자 행동 분석, 광고 캠페인 현황 모니터링
- **특징**: 데이터 발생부터 분석까지의 지연 시간을 최소화하여 즉각적인 인사이트 제공

# 22. 파이프라인은 상황에 따른 선택일 뿐

- 위에서 소개한 두 가지 파이프라인은 대표적인 구성일 뿐, 절대적인 규칙이 아님
- 실제 비지니스 환경에서는 주어진 조건에 맞춰 기술 요소를 유연하게 조합해야 함

### **BI나 대시보드 툴은 다양한 소스를 지원한다**

- “BI 리포트는 반드시 데이터 웨어하우스(DW)에 연결해야 한다”와 같은 규칙은 없음
- 만약, “실시간 현황 보고”가 최종 목표라면, BI를 Druid나 운영 DB에 직접 연결하는게 효율적
- 만약, “월별 수익 그래프”가 최종 목표라면, 대시보드를 RedShift에 직접 연결하는게 효율적

### **데이터의 '성격'에 맞는 OLAP을 선택해야 한다.**

- "데이터가 크면 무조건 Redshift 같은 DW를 써야 한다”와 같은 규칙은 없음
- 만약, "복잡한 조인"보다 "시간 흐름에 따른 분석"이 더 중요하다면, 데이터 볼륨이 크더라도 Redshift 대신 Druid가 더 나은 선택

### ETL은 목적에 맞게 자유롭게 조합할 수 있다.

- 처리 방식(ETL)이 적재할 저장소(OLAP)를 결정짓는 규칙은 없음
- 만약, “시간별 분석”이 더 중요하다면, 대용량 데이터를 Spark로 한 번에 변환한 뒤, 그 결과를 Druid에 저장하고 사용하는게 효율적
- 만약, “복잡한 통합 분석”이 필요하다면, Flink(스트리밍)로 정제한 데이터를 모아, Spark(배치)로 다시 처리하는 게 효율적

# 23. 그럼, 고민해보자

## 자네, 사이의 ‘스침’ 서비스에 대해서 아는가?

- 사이의 ‘스침’은 핵심 서비스로 사용자의 실시간 위치를 파악해, 물리적으로 가까운 거리를 스쳐 지난간 다른 사용자들과의 상호작용을 기록하고 피드 형태로 보여주는 서비스

### 스침 서비스

- 플로우
    - 클라이언트로부터 주기적으로 현재 GPS 좌표를 서버의 API 엔트포인트로 전송(HTTP)
    - 레디스의 ZSet(Sorted Set)에 사용자의 위도, 경도를 지속적으로 갱신
    - 바운딩 박스 쿼리 전략으로 주변 유저를 검색
    - 스침 이벤트를 레디스 Set에 저장하여, 중복 방지
    - 스침 이벤트를 RDBMS에 영구 기록
- 전략
    - **Redis ZSet**을 '바운딩 박스' 검색 엔진으로 활용
    - ZSet은 Score값을 기반으로 O(logN)의 빠른 범위 검색을 지원
- 참고
    - 레디스의 GEO기능을 활용하면 위도, 경도를 하나의 Scorce로 변환 가능
        - Geohash는 두 좌표를 하나의 값으로 합쳐서 한번에 범위 검색이 가능하도록 돕는 알고리즘

# 24. OLAP를 추가한 플로우를 설계해보자

- 어떤 ETL을 선택하면 좋을까?
- ETL에선 어떤 작업을 처리해야 할까?
- 어떤 OLAP를 선택하면 좋을까?
- 완성된 데이터를 OLAP에 저장하는게 좋을까? 아니면, OLAP의 쿼리 성능을 통해 완성된 데이터를 생성하는게 좋을까?

# 25. 이 과정을 통해 획득하게 되는 데이터로 무엇을 더 할 수 있을까?

**어떤 비즈니스적 가치를 창출할 수 있을까?**

- 사람들의 위치 정보를 활용해 **거리 트렌드 분석**이나 **유동인구 분석**에 활용할 수 있지 않을까?
- 러닝 앱의 경우, 사용자의 러닝 경로에 있는 지역 음식점이나 카페 방문을 유도하는 **위치 기반 마케팅**을 할 수 있지 않을까?