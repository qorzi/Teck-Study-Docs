# 1. 일괄 처리(Batch Processing)란 무엇인가

- 데이터 처리 아키텍처는 데이터를 다루는 시점과 방식에 따라 크게 세 가지로 분류됨
    - **서비스(온라인)**: 사용자의 요청에 즉시 응답
    - **스트림 처리(준실시간)**: 발생하는 이벤트를 실시간으로 계속 처리
    - **일괄 처리(오프라인)**: 이 글의 주제로, 다른 두 방식과 근본적으로 다른 접근 방식을 취함
- 일괄 처리 시스템의 핵심 정의는 **크기가 정해진 유한한(bounded) 데이터 입력**을 받는다는 것
    - 입력 데이터 전체를 한 번에 처리하는 것을 전제로 함
    - 작업은 보통 비동기적으로 수행되며, 주된 성능 목표는 응답 시간이 아닌 **처리량(Throughput)**

# 2. 배치 처리와 유닉스(Unix) 철학

- 현대 분산 배치 처리 시스템의 많은 원칙은 유닉스 철학에 뿌리를 둠
- **각 프로그램은 한 가지 일을 잘하도록 만든다**
    - `awk`, `sort`, `uniq` 등 작고 전문화된 도구를 파이프(`|`)로 연결해 복잡한 작업을 수행
- **모든 프로그램의 출력은 다른 프로그램의 입력이 될 것으로 예상한다**
    - 표준 입력(`stdin`)과 표준 출력(`stdout`)이라는 단순한 인터페이스로 프로그램들을 느슨하게 결합(loose coupling)
- **입력의 불변성(Immutability)**
    - 유닉스 도구는 입력 파일을 절대 수정하지 않고, 항상 새로운 출력 스트림을 생성
    - 이 원칙은 작업의 안정성과 재현 가능성을 보장

# 3. 맵리듀스(MapReduce) 패러다임

- 유닉스 철학을 분산 환경으로 확장하고 **내고장성(Fault Tolerance)**을 더한 모델
- **상태 비저장(Stateless) 함수**
    - 개발자가 작성하는 `map`과 `reduce` 함수는 이전 호출의 결과를 기억하거나 외부 상태에 의존하지 않음
    - 동일한 입력에 대해 항상 동일한 출력을 보장하는 **결정론적(deterministic)** 함수
- **관심사의 분리(Separation of Concerns)**
    - **개발자**: 데이터 처리 로직(`map`, `reduce` 함수)에만 집중
    - **프레임워크**: 분산 실행, 스케줄링, 장애 복구 등 복잡한 시스템 문제를 전담
    - 이 분리 덕분에 분산 프로그래밍의 진입 장벽이 극적으로 낮아짐

# 4. 데이터 지역성(Data Locality)의 원리

- **"연산은 데이터가 있는 곳으로 이동한다 (Computation moves to the data)"**
- 맵리듀스 프레임워크는 네트워크를 통한 대용량 데이터 전송이 가장 큰 병목임을 인지
- **동작 방식**
    - 작업을 시작하기 전, 스케줄러는 HDFS의 NameNode에 문의하여 입력 데이터 블록들이 어느 DataNode에 저장되어 있는지 파악
    - 이후 맵 태스크를 해당 데이터가 저장된 DataNode에서 직접 실행하도록 스케줄링
- **효과**: 네트워크 I/O를 최소화하고, 클러스터 전체의 대역폭을 보존하여 처리 성능을 극대화

# 5. 맵리듀스 데이터 흐름: 4단계 작업

- **1단계: 입력 분할 (Input Split)**
    - HDFS의 대용량 입력 파일을 정해진 크기의 조각으로 나눔
    - 각 조각은 하나의 `맵 태스크`에 할당됨
- **2단계: 맵 (Map)**
    - `매퍼 함수`가 각 데이터 레코드에 대해 독립적으로 병렬 실행
    - 입력에서 `<키, 값>` 쌍을 추출하여 로컬 디스크에 임시 저장
- **3단계: 셔플 및 정렬 (Shuffle & Sort)**
    - 맵리듀스 프레임워크의 심장. 여러 하위 단계로 구성됨
    - **파티셔닝**:
        - 키의 해시값을 계산(`key.hashCode() % numReducers`)하여 특정 `리듀서`에 데이터를 할당.
        - **같은 키는 반드시 같은 리듀서로** 보내짐을 보장
    - **정렬**: 각 리듀서는 자신에게 할당된 데이터를 키 순서대로 정렬
- **4단계: 리듀스 (Reduce)**
    - `리듀서 함수`가 고유 키와 해당 키의 값 목록을 입력으로 받아 최종 결과를 집계/요약
    - 최종 결과는 다시 HDFS에 영속적으로 저장됨

# 6. 콤바이너(Combiner) 최적화

- **"네트워크로 보내기 전에 로컬에서 먼저 집계하자"**
- 맵 태스크와 리듀스 태스크 사이의 네트워크 데이터 전송량을 줄이기 위한 중요한 최적화 기법
- **동작 방식**
    - 각 맵 태스크가 끝난 후, 셔플 단계로 데이터를 보내기 전에 로컬 노드에서 먼저 실행되는 **미니 리듀서(mini-reducer)**
    - 맵의 출력 중 일부를 미리 집계하여 네트워크로 전송해야 할 데이터의 양을 줄임
- **제약 조건**: `SUM`, `COUNT`처럼 순서에 상관없이 결과가 같은 **결합 법칙과 교환 법칙이 성립하는 연산**에만 적용 가능

# 7. 대용량 데이터 처리와 조인 알고리즘

- 맵리듀스가 다루는 데이터는 단일 장비의 메모리에 한 번에 로드하기 어려울 정도로 매우 큼
- 따라서 데이터를 효율적으로 조인하기 위한 특별한 전략이 필요
- **정렬-병합 조인 (Sort-Merge Join)**
    - **리듀스 사이드 조인**의 대표적인 방식
    - 조인할 키를 맵의 키로 삼아 셔플 단계에서 관련 데이터를 모두 같은 리듀서로 모음
    - 데이터가 이미 키로 정렬되어 있으므로, 리듀서는 정렬된 목록을 병합하며 조인 수행
- **브로드캐스트 해시 조인 (Broadcast Hash Join)**
    - **맵 사이드 조인**의 한 방식
    - 조인할 데이터셋 중 하나가 메모리에 들어갈 만큼 작을 때 사용
    - 작은 데이터셋을 모든 매퍼에 미리 복제/전송하고, 매퍼는 이를 메모리에 올려둔 채 큰 데이터셋을 읽으며 즉시 조인
- **파티션 해시 조인 (Partitioned Hash Join)**
    - **맵 사이드 조인**의 다른 방식
    - 두 데이터셋 모두 크지만, **같은 키를 기준으로 동일하게 파티셔닝**되어 있을 때 사용
    - 각 매퍼는 두 데이터셋의 상응하는 파티션만 읽어 로컬에서 조인 수행

# 8. 데이터 쏠림(Data Skew) 현상과 해결책

- **정의**: 특정 키에 데이터가 비정상적으로 몰리는 현상 (`Hot Key` 문제)
- **문제점**: 핫 키를 처리하는 **단 하나의 리듀서가 병목(Hotspot)**이 되어, 다른 모든 리듀서가 작업을 끝내도 그 하나를 기다리느라 전체 작업이 끝나지 않음
- **해결책: 솔팅 (Salting)**
    - **원리**: 핫 키를 여러 리듀서로 분산시켜 병렬 처리
    - **동작 방식**
        1. 핫 키에 랜덤한 접미사(salt)를 붙여 `(기존 키)_(랜덤 값)` 형태의 새로운 키를 생성
        2. 이제 데이터가 여러 리듀서로 분산됨. 각 리듀서는 부분 집계를 수행
        3. 모든 부분 집계가 끝나면, 추가적인 맵리듀스 작업을 통해 접미사를 제거하고 최종 결과를 합산

# 9. 워크플로와 중간 상태 구체화

- **유닉스 파이프 vs 맵리듀스 워크플로**
    - **유닉스**: 파이프를 통해 작은 인메모리 버퍼로 데이터를 스트리밍. 빠르지만 내고장성이 없음
    - **맵리듀스**:
        - 여러 작업을 연결할 때, 프레임워크 차원의 파이프라인을 지원하지 않음.
        - 개발자가 HDFS 상의 입출력 디렉터리를 수동으로 연결해 워크플로를 구축해야 함
- **중간 상태 구체화 (Intermediate State Materialization)**
    - 맵리듀스는 각 작업의 결과를 다음 작업의 입력으로 사용하기 위해 **HDFS에 파일로 기록**함
    - 이는 내고장성을 확보하기 위한 설계적 선택. 작업 실패 시 HDFS에 저장된 중간 결과로부터 안전하게 복구 가능
    - 하지만 이 방식은 맵리듀스의 가장 큰 성능 병목의 원인이 됨

# 10. 일괄 처리 출력의 철학

- **입력은 불변, 출력은 원자적(Atomic) 생성**
    - 맵리듀스 작업은 원본 데이터를 절대 건드리지 않음. 항상 새로운 디렉터리에 결과를 생성.
    - **성공한 결과만 저장**:
        - 맵리듀스 프레임워크는 작업이 100% 성공적으로 완료되었을 때만 출력 디렉터리를 최종적으로 생성하거나 공개함.
        - 작업이 중간에 실패하면, 지금까지 생성된 모든 불완전한 출력 파일은 폐기됨.
        - 이는 소비자가 오염되거나 불완전한 데이터를 보는 것을 원천적으로 차단.
- **멱등성(Idempotency)과 인적 내결함성**
    - 위 두 원칙(불변 입력 + 원자적 출력) 덕분에, 작업이 실패하거나 코드에 버그가 있어도, 동일한 입력으로 작업을 재실행하면 항상 동일한 결과를 얻을 수 있음.
    - 이는 잘못된 출력을 간단히 삭제하고 재실행하면 되므로, 개발자가 실수를 두려워하지 않고 빠르게 실험하고 개발할 수 있는 환경을 제공.

# 11. 스키마 온 리드와 데이터 레이크 철학

- **MPP 데이터베이스 vs HDFS**
    - 전통적인 MPP(대규모 병렬 처리) 데이터베이스는 **스키마 온 라이트(Schema-on-Write)** 방식을 사용. 데이터를 저장하기 전에 반드시 사전 정의된 스키마(테이블 구조)에 맞춰 데이터를 정제하고 변환해야 함
    - 반면 HDFS와 같은 분산 파일 시스템은 스키마를 강제하지 않음. 어떤 형식이든 원시 데이터(raw data)를 그대로 저장
- **스키마 온 리드 (Schema-on-Read)**
    - HDFS의 철학. 데이터의 구조나 의미를 저장 시점이 아닌, **읽는 시점(on-read)**에 해석하고 적용
    - 데이터 생산자는 데이터 형식에 구애받지 않고 빠르게 데이터를 쏟아내기만 하면 됨. 데이터를 어떻게 해석하고 활용할지는 전적으로 데이터를 소비하는 애플리케이션의 책임
- **데이터 레이크(Data Lake)와 디커플링**
    - 이 철학은 "원시 데이터를 일단 모두 수집하고, 스키마 설계는 나중에 고민하자"는 **데이터 레이크** 개념으로 이어짐
    - 데이터 수집 속도를 극대화하고, 생산자와 소비자를 완벽하게 분리(decoupling)함
    - 하나의 원시 데이터 소스를 여러 다른 목적을 가진 소비자들이 각자의 필요에 맞게 다양한 방식으로 해석하고 사용할 수 있는 유연성을 제공

# 12. 맵리듀스의 문제점

- **중간 상태 구체화의 비효율성**
    - 매 작업마다 디스크에 중간 결과를 쓰고 다시 읽는 과정은 막대한 I/O 비용과 지연 시간을 유발
- **2단계 모델의 경직성**
    - `맵 -> 리듀스`라는 고정된 모델은 머신러닝의 반복 알고리즘이나 복잡한 데이터 흐름을 표현하기에 너무 단순하고 비효율적
- **높은 개발 복잡성**
    - 조인, 데이터 쏠림(skew) 처리 등을 위해 개발자가 복잡한 수동 최적화를 수행해야 함

# 13. 데이터플로 엔진의 등장

- 맵리듀스의 한계를 극복하기 위해 **Spark, Flink** 같은 차세대 **데이터플로 엔진**이 등장
- **차이점**
    - **워크플로 표현**: 맵리듀스가 `작업의 연속`으로 워크플로를 본 반면, 데이터플로 엔진은 전체 워크플로를 하나의 **방향성 비순환 그래프(DAG)**로 표현하고 전역적으로 최적화
    - **중간 데이터 처리**: 디스크에 기록하는 대신, **인메모리**에서 데이터를 다음 단계로 직접 전달하여 I/O 병목을 제거
    - **유연한 연산자**: `map`, `filter`, `join` 등 풍부하고 유연한 연산자를 제공하여, 불필요한 정렬이나 셔플을 생략하고 복잡한 로직을 쉽게 표현 가능

# 14. 데이터플로 엔진의 내고장성 방식

- **"중간 저장을 안 하는데 어떻게 장애를 복구하는가?"**
- 데이터플로 엔진은 데이터 변환 과정을 추적하여 장애 발생 시 데이터를 재계산하는 방식을 사용
- **Spark의 RDD와 계보(Lineage)**
    - **RDD(Resilient Distributed Dataset)**: 데이터셋을 나타내는 불변 객체
    - **계보(Lineage)**: RDD가 어떤 부모 RDD로부터 어떤 변환을 통해 만들어졌는지에 대한 모든 기록
    - 노드 장애로 특정 데이터 파티션이 유실되면, 프레임워크는 계보를 따라 원본 데이터로부터 해당 파티션만 정확하게 재계산
- **Flink의 분산 스냅샷 (체크포인트)**
    - 작업이 실행되는 동안, 모든 연산자의 상태를 주기적으로 지속성 있는 저장소에 스냅샷으로 저장
    - 장애 발생 시, 가장 최근의 성공적인 스냅샷으로부터 작업을 재시작

# 15. 워크플로 스케줄러 (Oozie, Airflow)

- **"누가 이 모든 작업을 순서대로 실행하고 관리하는가?"**
- 맵리듀스나 Spark 작업은 단일 '실행 단위'일 뿐, 실제 데이터 파이프라인은 수많은 작업의 복잡한 의존성으로 구성됨
- **워크플로 스케줄러의 역할**
    - **의존성 관리**: A 작업이 성공해야 B와 C를 실행하고, B와 C가 모두 성공해야 D를 실행하는 등의 복잡한 흐름을 정의
    - **스케줄링**: 매일 새벽 2시에 파이프라인을 실행하는 등 주기적인 실행을 관리
    - **모니터링 및 알림**: 작업 실패 시 담당자에게 알림을 보내고, 재시도 정책을 관리
- **대표 도구**: **Apache Oozie** (하둡 생태계에 특화), **Apache Airflow** (범용적이며 Python 코드로 파이프라인 정의)