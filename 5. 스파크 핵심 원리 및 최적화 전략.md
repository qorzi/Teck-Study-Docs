# 1. 스파크 성능의 원천

아파치 스파크의 고성능은 데이터를 처리하는 방식인 분산 자료구조와 연산을 최적화하는 내부 엔진에 기반함.

- **핵심 자료구조:** RDD, DataFrame, Dataset
- **핵심 최적화 엔진:** Catalyst, Tungsten

# 2. 스파크의 3대 자료구조 비교

스파크는 RDD, DataFrame, Dataset이라는 세 가지 핵심 자료구조를 통해 데이터를 처리함.

| 구분 | RDD | DataFrame | Dataset |
| --- | --- | --- | --- |
| **최적화** | 수동 (X) | 자동 (O) | 자동 (O) |
| **데이터 관리** | JVM 객체 | 네이티브 메모리 | 네이티브 메모리 |
| **API** | 저수준 | 고수준 | 고수준 + 저수준 |
| **스키마** | 없음 | 있음 | 있음 (타입 체크) |

# 3. 자료구조 1: RDD (Resilient Distributed Dataset)

- **특징:** 스파크 초기 자료구조. JVM 힙 메모리에 Java/Scala 객체로 데이터 저장.
- **최적화:** Catalyst, Tungsten 최적화 혜택 없음. 개발자가 직접 모든 최적화 로직 구현해야 함.
- **API:** `map`, `filter` 등 저수준 함수형 API. 데이터 처리를 세밀하게 제어 가능.
- **스키마:** 스키마 정보가 없어 컴파일 시점 타입 체크 불가.
- **주 사용처:** 비정형 데이터 처리 또는 매우 세밀한 저수준 제어가 필요할 때.

# 4. 자료구조 2: DataFrame

- **특징:** 구조화된 데이터를 표현하는 테이블 형태의 자료구조. 사실상 `Dataset`의 별칭.
- **최적화:** Catalyst와 Tungsten 엔진의 자동 최적화 혜택을 받음.
- **데이터 관리:** Tungsten을 통해 데이터를 JVM 밖 네이티브 메모리(Off-Heap)에 Unsafe Row 포맷으로 관리. GC 오버헤드를 원천적으로 회피하여 성능 극대화.
- **API:** `select`, `groupBy` 등 고수준 선언적 API 및 SQL 사용. '무엇을' 할지만 정의하면 스파크가 '어떻게' 할지 최적화.
- **스키마:** 스키마 정보를 가지며, 이를 기반으로 Catalyst가 최적화 수행.
- **주 사용처:** 대부분의 정형/반정형 데이터 분석, ETL, BI, 머신러닝 등 고성능이 요구되는 모든 작업.

# 5. 자료구조 3: Dataset

- **특징:** DataFrame에 타입 안정성(Type Safety)을 더한 자료구조.
- **장점:** 컴파일 시점에 데이터 타입을 체크해 런타임 오류를 사전에 방지. 복잡한 비즈니스 로직 구현 시 코드 안정성 향상.
- **API:** DataFrame의 고수준 API와 RDD의 함수형 API를 함께 사용 가능.
- **언어 제한:** 핵심 장점인 타입 안정성은 Scala, Java 같은 정적 타입 언어에서만 유효. Python에서는 일반적으로 DataFrame 사용.

# 6. 실행 계획의 청사진: DAG (Directed Acyclic Graph)

- **정의:** 연산들의 의존 관계를 표현한 실행 계획. 각 연산은 노드, 데이터 흐름은 간선.
- **특징:** 액션(Action)이 호출될 때마다 하나의 Job이 생성되고, 각 Job은 하나의 DAG를 가짐.

# 7. 연산의 종류 1: Transformation (변환)

- **정의:** 원본 데이터를 가공해 새로운 RDD/DataFrame/Dataset을 생성하는 연산. **지연 평가(Lazy Evaluation)**됨.
- **종류:**
    - **Narrow Transformation (좁은 변환):** 1:1 변환. 입력 파티션 하나가 출력 파티션 하나에만 영향을 줌. 셔플(Shuffle)이 발생하지 않음. (예: `map`, `filter`)
    - **Wide Transformation (넓은 변환):** N:M 변환. 하나의 출력 파티션을 위해 여러 입력 파티션의 데이터가 필요. 파티션 간 데이터 재분배, 즉 **셔플(Shuffle)**이 발생. (예: `groupByKey`, `reduceByKey`, `join`)

# 8. 성능 병목의 주범: Shuffle (셔플)

- **정의:** Wide Transformation 수행 시, 네트워크를 통해 파티션 간 데이터를 재분배하는 과정.
- **특징:** 상당한 디스크 및 네트워크 I/O를 유발하는 성능 병목의 주범.
- **Stage 분할 기준:** 스파크는 DAG 내에서 셔플이 발생하는 지점을 기준으로 작업을 Stage 단위로 분할함.

# 9. 실행의 방아쇠: Action (액션)

- **정의:** 지연 평가되던 변환 작업들을 실제로 실행시키는 트리거.
- **역할:** 액션이 호출되면 Job이 생성되고, DAG가 스케줄러에 제출되어 클러스터에서 실행됨.
- **예시:** `count()`, `collect()`, `show()`, `save()`

# 10. 작업의 실행 단위: Job, Stage, Task

- **Job:** 하나의 Action에 의해 생성되는 전체 작업 단위.
- **Stage:** Job 내부에서 Shuffle을 기준으로 나뉘는 작업 단계.
- **Task:** Stage 내에서 데이터 파티션 단위로 쪼개지는 가장 작은 실행 단위. 각 Task는 하나의 Executor 코어에서 실행됨.

# 11. 전체 실행 흐름 요약

스파크의 모든 작업은 지연 평가(Lazy Evaluation) 원칙에 따라, Action이 호출되기 전까지는 실행 계획(DAG)만 생성하고 실제 연산은 수행하지 않음.

**코드 예제:**

```python
# 'Sales' 부서 직원을 필터링하고 보너스 10% 추가
sales_df = df.filter(col("department") == "Sales")
bonus_df = sales_df.withColumn("bonus", col("salary") * 0.1)

# show() 액션이 호출되는 순간, 모든 작업이 시작됨.
bonus_df.show()
```

**내부 과정:**

1. **Job 생성:** `show()` Action 호출 시 Job 생성.
2. **DAG 생성:** `createDataFrame` → `filter` → `withColumn` → `show`로 이어지는 연산 의존 관계(DAG) 생성.
3. **Stage 분할:** `filter`, `withColumn`은 Narrow Transformation이므로 Shuffle 없음. 전체 작업이 단일 Stage로 구성.
4. **Task 생성 및 실행:** 데이터 파티션별로 `filter`, `withColumn`을 수행할 Task 생성. Task들이 Executor에 분배되어 병렬 실행.
5. **결과 취합:** 각 Task의 실행 결과가 드라이버로 모아져 최종 결과가 화면에 표시됨.

# 12. 최적화 엔진 1: Catalyst (카탈리스트)

- **역할:** 쿼리 최적화 엔진(Query Optimizer).
- **기능:**
    - **분석(Analysis):** SQL, DataFrame 코드를 분석해 논리적 실행 계획 생성.
    - **논리적 최적화(Logical Optimization):** 규칙 기반 최적화 수행 (Predicate Pushdown, Column Pruning 등).
    - **물리적 계획 수립(Physical Planning):** 비용 기반 최적화를 통해 최적의 조인 방식 등 선택.
    - **코드 생성(Code Generation):** 최종 물리 계획을 Tungsten이 실행할 Java 바이트코드로 변환.

# 13. 최적화 엔진 2: Tungsten (텅스텐)

- **역할:** JVM의 한계를 넘어선 물리적 실행 엔진.
- **주요 기술:**
    - **네이티브 메모리 관리 (Off-Heap):** 데이터를 JVM 힙이 아닌 OS 네이티브 메모리에 Unsafe Row 포맷으로 직접 저장. GC 오버헤드 회피 및 CPU 캐시 효율 극대화.
    - **전체 단계 코드 생성 (Whole-Stage Code Generation):** 여러 연산을 하나의 최적화된 Java 바이트코드로 동적 생성. 가상 함수 호출 오버헤드 제거.

# 14. Spark SQL의 데이터 관리: 테이블과 뷰

스파크 SQL에서는 데이터를 테이블 또는 뷰 형태로 다루며, 각 요소는 데이터의 저장 위치와 생명주기에 따라 구분됨.

| 구분 (유형) | 저장 위치 | 데이터 파일 관리 | 메타데이터 관리 | DROP 시 처리 |
| --- | --- | --- | --- | --- |
| **관리형 테이블** | 내부 지정 경로 | Spark가 직접 관리 | Spark가 직접 관리 | 데이터와 메타데이터 모두 삭제 |
| **비관리형 테이블** | 외부 지정 경로(S3 등) | 사용자/외부 시스템 | Spark는 위치 정보만 | 메타데이터만 삭제 (원본 데이터 보존) |
| **임시 뷰** | 메모리 (세션 범위) | 저장 안 함 | 저장 안 함 | 세션 종료 시 자동 소멸 |
| **글로벌 임시 뷰** | 메모리 (앱 범위) | 저장 안 함 | 저장 안 함 | 애플리케이션 종료 시 자동 소멸 |

# 15. 성능 최적화 1: UDF 및 RDD-like API 사용 최소화

- **문제점:**
    - UDF나 `DataFrame.rdd.map()` 같은 RDD-like API 사용은 Catalyst, Tungsten 최적화 엔진을 우회함.
    - 직렬화/역직렬화, Python 프로세스 통신, GC 오버헤드로 막대한 비용 발생.
- **해결책:**
    - **내장 함수 우선 사용:** 가능한 모든 연산은 스파크 SQL 내장 함수와 DataFrame의 고수준 API(DSL)로 처리.
    - **Pandas UDF 고려:** Python UDF가 불가피하다면, 벡터화 연산을 수행하는 Pandas UDF(Vectorized UDF)를 사용해 직렬화 비용 감소.

# 16. 성능 최적화 2: 조인 전략 이해 - Broadcast Hash Join (BHJ)

- **조건:** 한쪽 테이블이 다른 쪽에 비해 매우 작을 때 (기본 10MB, `spark.sql.autoBroadcastJoinThreshold`로 설정 가능).
- **동작:**
    - 작은 테이블을 모든 Executor의 메모리에 복사(Broadcast)한 후, 큰 테이블의 파티션 내에서 맵사이드 조인 수행.
    - 셔플이 발생하지 않아 가장 빠름.

# 17. 성능 최적화 3: 조인 전략 이해 - Shuffle Sort Merge Join (SSMJ)

- **조건:** 두 테이블이 모두 클 때.
- **동작:**
    - **Shuffle:** 조인 키를 기준으로 두 테이블의 데이터를 재파티셔닝.
    - **Sort:** 각 파티션 내에서 조인 키를 기준으로 데이터 정렬.
    - **Merge:** 정렬된 데이터를 순차적으로 병합하며 조인.
- **최적화:** 조인 키를 기준으로 미리 버켓팅(Bucketing)된 테이블을 사용하면 Shuffle 단계를 생략하여 성능 향상 가능.

# 18. 성능 최적화 4: Cache 및 Persist 활용

- **동작:** `cache()`, `persist()`는 Transformation이며, 액션이 호출될 때 실제 데이터가 메모리나 디스크에 저장됨.
- **사용 시점:**
    - 동일한 DataFrame을 여러 번의 액션에서 반복적으로 사용할 때.
    - 복잡한 변환을 거친 중간 결과를 저장해 재사용할 때 (특히 머신러닝 반복 학습).
- **주의할 점:**
    - 자주 사용하지 않거나, 변환 비용이 적은 데이터에 사용하면 오히려 오버헤드 발생.
    - 무분별한 사용은 메모리 부족(OOM)의 원인이 됨.

# 19. 정형화 스트리밍: 핵심 철학

정형화 스트리밍은 배치(Batch) 처리와 스트림(Stream) 처리를 단일 API로 통합함.

- **프로그래밍 모델:** 데이터 스트림을 '무한히 데이터가 추가되는 테이블'로 간주. 익숙한 배치 처리 방식(DataFrame/SQL)으로 쿼리 작성.
- **실행 모델 (마이크로 배치):** 배치 쿼리를 '증분 실행 계획'으로 자동 변환. 정해진 트리거 간격마다 새로 도착한 데이터를 작은 배치로 묶어 처리.
- **장점:** 스파크의 장애 복구 및 스케줄링 기능을 그대로 활용. **정확히 한 번 처리(Exactly-Once Semantics)** 보장 용이.

# 20. 스트리밍의 상태 관리와 워터마킹

- **상태 유지(Stateful) 연산:** `groupBy`, `agg`, `join` 등 여러 레코드에 걸쳐 중간 결과를 유지(상태)해야 하는 연산.
- **워터마킹 (Watermarking):** 상태 유지가 필요한 연산에서 무한정 상태가 커지는 것을 방지하는 핵심 기능.
    - **역할:** 이벤트 시간을 기준으로 '얼마나 늦게 도착하는 데이터까지 허용할 것인가'에 대한 임계값 설정.
    - **동작:** `withWatermark("event_time", "10 minutes")` 설정 시, 관측된 최대 이벤트 시간보다 10분 이상 늦게 도착하는 데이터는 버림. 오래된 상태 정보를 메모리에서 안전하게 제거 가능.

# 21. 스트리밍의 장애 복구

스파크는 체크포인트를 통해 상태 정보를 안정적으로 관리하고 장애 발생 시 복구함.

- **상태 저장:** 각 마이크로 배치를 처리하며 생성된 상태 정보는 지정된 체크포인트 위치(HDFS, S3 등)에 버전별로 저장됨.
- **오프셋 로깅:** 처리한 데이터의 범위(Offset)는 WAL(Write-Ahead-Log)에 먼저 기록됨.
- **장애 발생 및 복구:** 장애 발생 시, 체크포인트에서 마지막으로 성공한 상태를 복구하고, WAL을 참조하여 실패한 배치부터 데이터 처리를 재시작.

# 22. 스트림-스트림 조인 (Stream-Stream Join)

- **고려사항:** 이벤트 순서 뒤바뀜, 이벤트 간 시간 간격 존재.
- **내부 조인 (Inner Join):**
    - **동작:** 양쪽 스트림 데이터를 상태 저장소에 버퍼링하고 조인.
    - **상태 관리:** 워터마크와 이벤트 시간 제약 조건을 함께 사용해 오래된 상태 제거.
        - **워터마크:** `impressions.withWatermark("impressionTime", "1 hour")`
        - **시간 제약:** `expr("clickTime BETWEEN impressionTime AND impressionTime + interval 1 hour")`
- **외부 조인 (Outer Join):**
    - **상황:** 노출은 있었지만 클릭은 없는 경우 탐색.
    - **동작:** `LEFT OUTER JOIN` 사용. 워터마크 지정 필수.

# 23. 정확히 한 번 처리(Exactly-Once) 보장 조건

- **재실행 가능한 소스(Replayable Source):** Kafka 등. 실패 시 동일한 데이터 범위를 다시 읽을 수 있어야 함.
- **결정론적 연산(Deterministic Operations):** 동일한 입력에 대해 항상 동일한 결과를 내야 함.
- **멱등성 싱크(Idempotent Sink):** 재실행으로 중복된 결과가 쓰여도 최종 결과에 영향을 주지 않아야 함.